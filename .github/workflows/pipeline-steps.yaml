name: Reusable Pipeline Steps

on:
  workflow_call:
    inputs:
      start_date:
        description: 'Start date (YYYY-MM-DD)'
        required: true
        type: string
      end_date:
        description: 'End date (YYYY-MM-DD)'
        required: true
        type: string
      agencies:
        description: 'Filter agencies (comma-separated)'
        required: false
        type: string
      cogfy_wait_minutes:
        description: 'Minutes to wait for Cogfy processing'
        required: false
        type: string
        default: '20'

jobs:
  scraper:
    name: News Scraper
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
      packages: read
    steps:
      - name: Free disk space
        run: |
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache/CodeQL
          docker system prune -af

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/990583792367/locations/global/workloadIdentityPools/github-pool/providers/github-provider
          service_account: github-actions@inspire-7-finep.iam.gserviceaccount.com

      - name: Get secrets from Secret Manager
        id: secrets
        run: |
          echo "DATABASE_URL=$(gcloud secrets versions access latest --secret=govbrnews-postgres-connection-string)" >> $GITHUB_OUTPUT
          echo "HF_TOKEN=$(gcloud secrets versions access latest --secret=hf-token)" >> $GITHUB_OUTPUT

      - name: Run news scraper
        run: |
          AGENCIES_ARG=""
          if [ -n "${{ inputs.agencies }}" ]; then
            AGENCIES_ARG="--agencies ${{ inputs.agencies }}"
          fi
          docker run --rm \
            -e STORAGE_BACKEND=dual_write \
            -e DATABASE_URL="${{ steps.secrets.outputs.DATABASE_URL }}" \
            -e HF_TOKEN="${{ steps.secrets.outputs.HF_TOKEN }}" \
            ghcr.io/destaquesgovbr/data-platform:latest \
            data-platform scrape --start-date "${{ inputs.start_date }}" --end-date "${{ inputs.end_date }}" $AGENCIES_ARG
          echo "News scraper completed successfully"

  ebc-scraper:
    name: EBC News Scraper
    runs-on: ubuntu-latest
    needs: [scraper]
    permissions:
      contents: read
      id-token: write
      packages: read
    steps:
      - name: Free disk space
        run: |
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache/CodeQL
          docker system prune -af

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/990583792367/locations/global/workloadIdentityPools/github-pool/providers/github-provider
          service_account: github-actions@inspire-7-finep.iam.gserviceaccount.com

      - name: Get secrets from Secret Manager
        id: secrets
        run: |
          echo "DATABASE_URL=$(gcloud secrets versions access latest --secret=govbrnews-postgres-connection-string)" >> $GITHUB_OUTPUT
          echo "HF_TOKEN=$(gcloud secrets versions access latest --secret=hf-token)" >> $GITHUB_OUTPUT

      - name: Run EBC news scraper
        run: |
          docker run --rm \
            -e STORAGE_BACKEND=dual_write \
            -e DATABASE_URL="${{ steps.secrets.outputs.DATABASE_URL }}" \
            -e HF_TOKEN="${{ steps.secrets.outputs.HF_TOKEN }}" \
            ghcr.io/destaquesgovbr/data-platform:latest \
            data-platform scrape-ebc --start-date "${{ inputs.start_date }}" --end-date "${{ inputs.end_date }}" --allow-update
          echo "EBC news scraper completed successfully"

  upload-to-cogfy:
    name: Upload to Cogfy
    runs-on: ubuntu-latest
    needs: [scraper, ebc-scraper]
    permissions:
      contents: read
      id-token: write
      packages: read
    steps:
      - name: Free disk space
        run: |
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache/CodeQL
          docker system prune -af

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/990583792367/locations/global/workloadIdentityPools/github-pool/providers/github-provider
          service_account: github-actions@inspire-7-finep.iam.gserviceaccount.com

      - name: Get secrets from Secret Manager
        id: secrets
        run: |
          echo "DATABASE_URL=$(gcloud secrets versions access latest --secret=govbrnews-postgres-connection-string)" >> $GITHUB_OUTPUT
          echo "HF_TOKEN=$(gcloud secrets versions access latest --secret=hf-token)" >> $GITHUB_OUTPUT
          echo "COGFY_API_KEY=$(gcloud secrets versions access latest --secret=cogfy-api-key)" >> $GITHUB_OUTPUT

      - name: Upload news to Cogfy
        run: |
          docker run --rm \
            -e STORAGE_READ_FROM=postgres \
            -e DATABASE_URL="${{ steps.secrets.outputs.DATABASE_URL }}" \
            -e HF_TOKEN="${{ steps.secrets.outputs.HF_TOKEN }}" \
            -e COGFY_API_KEY="${{ steps.secrets.outputs.COGFY_API_KEY }}" \
            ghcr.io/destaquesgovbr/data-platform:latest \
            data-platform upload-cogfy --start-date "${{ inputs.start_date }}" --end-date "${{ inputs.end_date }}"
          echo "Upload to Cogfy completed successfully"

  enrich-themes:
    name: Enrich Dataset with AI Data
    runs-on: ubuntu-latest
    needs: [upload-to-cogfy]
    permissions:
      contents: read
      id-token: write
      packages: read
    steps:
      - name: Wait for Cogfy processing
        run: |
          WAIT_MINUTES=${{ inputs.cogfy_wait_minutes || '20' }}
          WAIT_SECONDS=$((WAIT_MINUTES * 60))
          echo "Waiting ${WAIT_MINUTES} minutes for Cogfy to process uploaded data..."
          echo "This allows time for Cogfy to complete vector embeddings and indexing"
          sleep ${WAIT_SECONDS}

      - name: Free disk space
        run: |
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache/CodeQL
          docker system prune -af

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/990583792367/locations/global/workloadIdentityPools/github-pool/providers/github-provider
          service_account: github-actions@inspire-7-finep.iam.gserviceaccount.com

      - name: Get secrets from Secret Manager
        id: secrets
        run: |
          echo "COGFY_API_KEY=$(gcloud secrets versions access latest --secret=cogfy-api-key)" >> $GITHUB_OUTPUT
          echo "DATABASE_URL=$(gcloud secrets versions access latest --secret=govbrnews-postgres-connection-string)" >> $GITHUB_OUTPUT
          echo "HF_TOKEN=$(gcloud secrets versions access latest --secret=hf-token)" >> $GITHUB_OUTPUT

      - name: Enrich dataset with AI-generated data
        run: |
          docker run --rm \
            -e COGFY_API_KEY="${{ steps.secrets.outputs.COGFY_API_KEY }}" \
            -e HF_TOKEN="${{ steps.secrets.outputs.HF_TOKEN }}" \
            -e STORAGE_BACKEND=dual_write \
            -e STORAGE_READ_FROM=postgres \
            -e DATABASE_URL="${{ steps.secrets.outputs.DATABASE_URL }}" \
            ghcr.io/destaquesgovbr/data-platform:latest \
            data-platform enrich --start-date "${{ inputs.start_date }}" --end-date "${{ inputs.end_date }}"
          echo "Dataset enrichment completed successfully"

  generate-embeddings:
    name: Generate Semantic Embeddings
    runs-on: ubuntu-latest
    needs: [enrich-themes]
    permissions:
      contents: read
      id-token: write
      packages: read
    steps:
      - name: Free disk space
        run: |
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache/CodeQL
          docker system prune -af

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/990583792367/locations/global/workloadIdentityPools/github-pool/providers/github-provider
          service_account: github-actions@inspire-7-finep.iam.gserviceaccount.com

      - name: Get secrets from Secret Manager
        id: secrets
        run: |
          echo "DATABASE_URL=$(gcloud secrets versions access latest --secret=govbrnews-postgres-connection-string)" >> $GITHUB_OUTPUT

      - name: Generate embeddings for news articles
        run: |
          docker run --rm \
            -e DATABASE_URL="${{ steps.secrets.outputs.DATABASE_URL }}" \
            ghcr.io/destaquesgovbr/data-platform:latest \
            data-platform generate-embeddings --start-date "${{ inputs.start_date }}" --end-date "${{ inputs.end_date }}"
          echo "Embedding generation completed successfully"

  sync-embeddings:
    name: Sync Embeddings to Typesense
    runs-on: ubuntu-latest
    needs: [generate-embeddings]
    permissions:
      contents: read
      id-token: write
      packages: read
    steps:
      - name: Free disk space
        run: |
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache/CodeQL
          docker system prune -af

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/990583792367/locations/global/workloadIdentityPools/github-pool/providers/github-provider
          service_account: github-actions@inspire-7-finep.iam.gserviceaccount.com

      - name: Get secrets from Secret Manager
        id: secrets
        run: |
          echo "DATABASE_URL=$(gcloud secrets versions access latest --secret=govbrnews-postgres-connection-string)" >> $GITHUB_OUTPUT
          TYPESENSE_CONN=$(gcloud secrets versions access latest --secret=typesense-write-conn)
          echo "TYPESENSE_HOST=$(echo $TYPESENSE_CONN | jq -r '.host')" >> $GITHUB_OUTPUT
          echo "TYPESENSE_PORT=$(echo $TYPESENSE_CONN | jq -r '.port')" >> $GITHUB_OUTPUT
          echo "TYPESENSE_API_KEY=$(echo $TYPESENSE_CONN | jq -r '.apiKey')" >> $GITHUB_OUTPUT

      - name: Sync embeddings to Typesense
        run: |
          docker run --rm \
            -e DATABASE_URL="${{ steps.secrets.outputs.DATABASE_URL }}" \
            -e TYPESENSE_HOST="${{ steps.secrets.outputs.TYPESENSE_HOST }}" \
            -e TYPESENSE_PORT="${{ steps.secrets.outputs.TYPESENSE_PORT }}" \
            -e TYPESENSE_API_KEY="${{ steps.secrets.outputs.TYPESENSE_API_KEY }}" \
            ghcr.io/destaquesgovbr/data-platform:latest \
            data-platform sync-embeddings-to-typesense --start-date "${{ inputs.start_date }}" --end-date "${{ inputs.end_date }}"
          echo "Typesense sync completed successfully"

  pipeline-summary:
    name: Pipeline Summary
    runs-on: ubuntu-latest
    needs: [scraper, ebc-scraper, upload-to-cogfy, enrich-themes, generate-embeddings, sync-embeddings]
    if: always()
    steps:
      - name: Pipeline completion summary
        run: |
          echo "=== News Processing Pipeline Summary ==="
          echo "Date range: ${{ inputs.start_date }} to ${{ inputs.end_date }}"
          echo "Scraper status: ${{ needs.scraper.result }}"
          echo "EBC Scraper status: ${{ needs.ebc-scraper.result }}"
          echo "Upload status: ${{ needs.upload-to-cogfy.result }}"
          echo "Dataset enrichment status: ${{ needs.enrich-themes.result }}"
          echo "Embedding generation status: ${{ needs.generate-embeddings.result }}"
          echo "Typesense sync status: ${{ needs.sync-embeddings.result }}"
          echo "============================================"

          if [ "${{ needs.scraper.result }}" = "success" ] && \
             [ "${{ needs.ebc-scraper.result }}" = "success" ] && \
             [ "${{ needs.upload-to-cogfy.result }}" = "success" ] && \
             [ "${{ needs.enrich-themes.result }}" = "success" ] && \
             [ "${{ needs.generate-embeddings.result }}" = "success" ] && \
             [ "${{ needs.sync-embeddings.result }}" = "success" ]; then
            echo "All pipeline stages completed successfully!"
            exit 0
          else
            echo "Pipeline had failures. Check individual job logs."
            exit 1
          fi
