name: Reusable Pipeline Steps

on:
  workflow_call:
    inputs:
      start_date:
        description: 'Start date (YYYY-MM-DD)'
        required: true
        type: string
      end_date:
        description: 'End date (YYYY-MM-DD)'
        required: true
        type: string
      agencies:
        description: 'Filter agencies (comma-separated)'
        required: false
        type: string
      cogfy_wait_minutes:
        description: 'Minutes to wait for Cogfy processing'
        required: false
        type: string
        default: '20'

jobs:
  scraper:
    name: News Scraper
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
      packages: read
    steps:
      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/990583792367/locations/global/workloadIdentityPools/github-pool/providers/github-provider
          service_account: github-actions@inspire-7-finep.iam.gserviceaccount.com

      - name: Get secrets from Secret Manager
        id: secrets
        run: |
          echo "DATABASE_URL=$(gcloud secrets versions access latest --secret=govbrnews-postgres-connection-string)" >> $GITHUB_OUTPUT
          echo "HF_TOKEN=$(gcloud secrets versions access latest --secret=hf-token)" >> $GITHUB_OUTPUT

      - name: Run news scraper
        run: |
          AGENCIES_ARG=""
          if [ -n "${{ inputs.agencies }}" ]; then
            AGENCIES_ARG="--agencies ${{ inputs.agencies }}"
          fi
          docker run --rm \
            -e STORAGE_BACKEND=dual_write \
            -e DATABASE_URL="${{ steps.secrets.outputs.DATABASE_URL }}" \
            -e HF_TOKEN="${{ steps.secrets.outputs.HF_TOKEN }}" \
            ghcr.io/destaquesgovbr/data-platform:latest \
            data-platform scrape --start-date "${{ inputs.start_date }}" --end-date "${{ inputs.end_date }}" $AGENCIES_ARG
          echo "News scraper completed successfully"

  ebc-scraper:
    name: EBC News Scraper
    runs-on: ubuntu-latest
    needs: [scraper]
    permissions:
      contents: read
      id-token: write
      packages: read
    steps:
      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/990583792367/locations/global/workloadIdentityPools/github-pool/providers/github-provider
          service_account: github-actions@inspire-7-finep.iam.gserviceaccount.com

      - name: Get secrets from Secret Manager
        id: secrets
        run: |
          echo "DATABASE_URL=$(gcloud secrets versions access latest --secret=govbrnews-postgres-connection-string)" >> $GITHUB_OUTPUT
          echo "HF_TOKEN=$(gcloud secrets versions access latest --secret=hf-token)" >> $GITHUB_OUTPUT

      - name: Run EBC news scraper
        run: |
          docker run --rm \
            -e STORAGE_BACKEND=dual_write \
            -e DATABASE_URL="${{ steps.secrets.outputs.DATABASE_URL }}" \
            -e HF_TOKEN="${{ steps.secrets.outputs.HF_TOKEN }}" \
            ghcr.io/destaquesgovbr/data-platform:latest \
            data-platform scrape-ebc --start-date "${{ inputs.start_date }}" --end-date "${{ inputs.end_date }}" --allow-update
          echo "EBC news scraper completed successfully"

  upload-to-cogfy:
    name: Upload to Cogfy
    runs-on: ubuntu-latest
    needs: [scraper, ebc-scraper]
    permissions:
      contents: read
      id-token: write
      packages: read
    steps:
      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/990583792367/locations/global/workloadIdentityPools/github-pool/providers/github-provider
          service_account: github-actions@inspire-7-finep.iam.gserviceaccount.com

      - name: Get secrets from Secret Manager
        id: secrets
        run: |
          echo "HF_TOKEN=$(gcloud secrets versions access latest --secret=hf-token)" >> $GITHUB_OUTPUT
          echo "COGFY_API_KEY=$(gcloud secrets versions access latest --secret=cogfy-api-key)" >> $GITHUB_OUTPUT

      - name: Upload news to Cogfy
        run: |
          docker run --rm \
            -e HF_TOKEN="${{ steps.secrets.outputs.HF_TOKEN }}" \
            -e COGFY_API_KEY="${{ steps.secrets.outputs.COGFY_API_KEY }}" \
            ghcr.io/destaquesgovbr/data-platform:latest \
            data-platform upload-cogfy --start-date "${{ inputs.start_date }}" --end-date "${{ inputs.end_date }}"
          echo "Upload to Cogfy completed successfully"

  enrich-themes:
    name: Enrich Dataset with AI Data
    runs-on: ubuntu-latest
    needs: [upload-to-cogfy]
    permissions:
      contents: read
      id-token: write
      packages: read
    steps:
      - name: Wait for Cogfy processing
        run: |
          WAIT_MINUTES=${{ inputs.cogfy_wait_minutes || '20' }}
          WAIT_SECONDS=$((WAIT_MINUTES * 60))
          echo "Waiting ${WAIT_MINUTES} minutes for Cogfy to process uploaded data..."
          echo "This allows time for Cogfy to complete vector embeddings and indexing"
          sleep ${WAIT_SECONDS}

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/990583792367/locations/global/workloadIdentityPools/github-pool/providers/github-provider
          service_account: github-actions@inspire-7-finep.iam.gserviceaccount.com

      - name: Get secrets from Secret Manager
        id: secrets
        run: |
          echo "COGFY_API_KEY=$(gcloud secrets versions access latest --secret=cogfy-api-key)" >> $GITHUB_OUTPUT
          echo "DATABASE_URL=$(gcloud secrets versions access latest --secret=govbrnews-postgres-connection-string)" >> $GITHUB_OUTPUT
          echo "HF_TOKEN=$(gcloud secrets versions access latest --secret=hf-token)" >> $GITHUB_OUTPUT

      - name: Enrich dataset with AI-generated data
        run: |
          docker run --rm \
            -e COGFY_API_KEY="${{ steps.secrets.outputs.COGFY_API_KEY }}" \
            -e HF_TOKEN="${{ steps.secrets.outputs.HF_TOKEN }}" \
            -e STORAGE_BACKEND=dual_write \
            -e DATABASE_URL="${{ steps.secrets.outputs.DATABASE_URL }}" \
            ghcr.io/destaquesgovbr/data-platform:latest \
            data-platform enrich --start-date "${{ inputs.start_date }}" --end-date "${{ inputs.end_date }}"
          echo "Dataset enrichment completed successfully"

  pipeline-summary:
    name: Pipeline Summary
    runs-on: ubuntu-latest
    needs: [scraper, ebc-scraper, upload-to-cogfy, enrich-themes]
    if: always()
    steps:
      - name: Pipeline completion summary
        run: |
          echo "=== News Processing Pipeline Summary ==="
          echo "Date range: ${{ inputs.start_date }} to ${{ inputs.end_date }}"
          echo "Scraper status: ${{ needs.scraper.result }}"
          echo "EBC Scraper status: ${{ needs.ebc-scraper.result }}"
          echo "Upload status: ${{ needs.upload-to-cogfy.result }}"
          echo "Dataset enrichment status: ${{ needs.enrich-themes.result }}"
          echo "============================================"

          if [ "${{ needs.scraper.result }}" = "success" ] && \
             [ "${{ needs.ebc-scraper.result }}" = "success" ] && \
             [ "${{ needs.upload-to-cogfy.result }}" = "success" ] && \
             [ "${{ needs.enrich-themes.result }}" = "success" ]; then
            echo "All pipeline stages completed successfully!"
            exit 0
          else
            echo "Pipeline had failures. Check individual job logs."
            exit 1
          fi
