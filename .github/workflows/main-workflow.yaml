name: Main News Processing Pipeline

on:
  schedule:
    # Runs every day at 4AM UTC (midnight Brasilia)
    - cron: '0 4 * * *'
  workflow_dispatch:
    inputs:
      start_date:
        description: 'Start date (YYYY-MM-DD)'
        required: false
        type: string
      end_date:
        description: 'End date (YYYY-MM-DD)'
        required: false
        type: string
      agencies:
        description: 'Filter agencies (comma-separated, e.g. mec,mds,agu)'
        required: false
        type: string
      cogfy_wait_minutes:
        description: 'Minutes to wait for Cogfy processing (default: 20)'
        required: false
        type: string
        default: '20'

permissions:
  contents: read
  id-token: write
  packages: read

jobs:
  setup-dates:
    name: Setup Date Variables
    runs-on: ubuntu-latest
    outputs:
      start_date: ${{ steps.dates.outputs.start_date }}
      end_date: ${{ steps.dates.outputs.end_date }}
    steps:
      - name: Set date variables
        id: dates
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ] && [ -n "${{ inputs.start_date }}" ]; then
            echo "start_date=${{ inputs.start_date }}" >> $GITHUB_OUTPUT
            echo "end_date=${{ inputs.end_date || inputs.start_date }}" >> $GITHUB_OUTPUT
          else
            echo "start_date=$(date -d '1 day ago' +'%Y-%m-%d')" >> $GITHUB_OUTPUT
            echo "end_date=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT
          fi

      - name: Print date information
        run: |
          echo "Pipeline will process from ${{ steps.dates.outputs.start_date }} to ${{ steps.dates.outputs.end_date }}"

  scraper:
    name: News Scraper
    runs-on: ubuntu-latest
    needs: [setup-dates]
    steps:
      - name: Free disk space
        run: |
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache/CodeQL
          docker system prune -af

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/990583792367/locations/global/workloadIdentityPools/github-pool/providers/github-provider
          service_account: github-actions@inspire-7-finep.iam.gserviceaccount.com

      - name: Get secrets from Secret Manager
        id: secrets
        run: |
          echo "DATABASE_URL=$(gcloud secrets versions access latest --secret=govbrnews-postgres-connection-string)" >> $GITHUB_OUTPUT
          echo "HF_TOKEN=$(gcloud secrets versions access latest --secret=hf-token)" >> $GITHUB_OUTPUT

      - name: Run news scraper
        run: |
          AGENCIES_ARG=""
          if [ -n "${{ inputs.agencies }}" ]; then
            AGENCIES_ARG="--agencies ${{ inputs.agencies }}"
          fi
          docker run --rm \
            -e STORAGE_BACKEND=dual_write \
            -e DATABASE_URL="${{ steps.secrets.outputs.DATABASE_URL }}" \
            -e HF_TOKEN="${{ steps.secrets.outputs.HF_TOKEN }}" \
            ghcr.io/destaquesgovbr/data-platform:latest \
            data-platform scrape --start-date "${{ needs.setup-dates.outputs.start_date }}" --end-date "${{ needs.setup-dates.outputs.end_date }}" $AGENCIES_ARG
          echo "News scraper completed successfully"

  ebc-scraper:
    name: EBC News Scraper
    runs-on: ubuntu-latest
    needs: [setup-dates, scraper]
    steps:
      - name: Free disk space
        run: |
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache/CodeQL
          docker system prune -af

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/990583792367/locations/global/workloadIdentityPools/github-pool/providers/github-provider
          service_account: github-actions@inspire-7-finep.iam.gserviceaccount.com

      - name: Get secrets from Secret Manager
        id: secrets
        run: |
          echo "DATABASE_URL=$(gcloud secrets versions access latest --secret=govbrnews-postgres-connection-string)" >> $GITHUB_OUTPUT
          echo "HF_TOKEN=$(gcloud secrets versions access latest --secret=hf-token)" >> $GITHUB_OUTPUT

      - name: Run EBC news scraper
        run: |
          docker run --rm \
            -e STORAGE_BACKEND=dual_write \
            -e DATABASE_URL="${{ steps.secrets.outputs.DATABASE_URL }}" \
            -e HF_TOKEN="${{ steps.secrets.outputs.HF_TOKEN }}" \
            ghcr.io/destaquesgovbr/data-platform:latest \
            data-platform scrape-ebc --start-date "${{ needs.setup-dates.outputs.start_date }}" --end-date "${{ needs.setup-dates.outputs.end_date }}" --allow-update
          echo "EBC news scraper completed successfully"

  upload-to-cogfy:
    name: Upload to Cogfy
    runs-on: ubuntu-latest
    needs: [setup-dates, scraper, ebc-scraper]
    steps:
      - name: Free disk space
        run: |
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache/CodeQL
          docker system prune -af

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/990583792367/locations/global/workloadIdentityPools/github-pool/providers/github-provider
          service_account: github-actions@inspire-7-finep.iam.gserviceaccount.com

      - name: Get secrets from Secret Manager
        id: secrets
        run: |
          echo "DATABASE_URL=$(gcloud secrets versions access latest --secret=govbrnews-postgres-connection-string)" >> $GITHUB_OUTPUT
          echo "HF_TOKEN=$(gcloud secrets versions access latest --secret=hf-token)" >> $GITHUB_OUTPUT
          echo "COGFY_API_KEY=$(gcloud secrets versions access latest --secret=cogfy-api-key)" >> $GITHUB_OUTPUT

      - name: Upload news to Cogfy
        run: |
          docker run --rm \
            -e STORAGE_READ_FROM=postgres \
            -e DATABASE_URL="${{ steps.secrets.outputs.DATABASE_URL }}" \
            -e HF_TOKEN="${{ steps.secrets.outputs.HF_TOKEN }}" \
            -e COGFY_API_KEY="${{ steps.secrets.outputs.COGFY_API_KEY }}" \
            ghcr.io/destaquesgovbr/data-platform:latest \
            data-platform upload-cogfy --start-date "${{ needs.setup-dates.outputs.start_date }}" --end-date "${{ needs.setup-dates.outputs.end_date }}"
          echo "Upload to Cogfy completed successfully"

  enrich-themes:
    name: Enrich Dataset with AI Data
    runs-on: ubuntu-latest
    needs: [setup-dates, upload-to-cogfy]
    steps:
      - name: Wait for Cogfy processing
        run: |
          WAIT_MINUTES=${{ inputs.cogfy_wait_minutes || '20' }}
          WAIT_SECONDS=$((WAIT_MINUTES * 60))
          echo "Waiting ${WAIT_MINUTES} minutes for Cogfy to process uploaded data..."
          echo "This allows time for Cogfy to complete vector embeddings and indexing"
          sleep ${WAIT_SECONDS}

      - name: Free disk space
        run: |
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache/CodeQL
          docker system prune -af

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/990583792367/locations/global/workloadIdentityPools/github-pool/providers/github-provider
          service_account: github-actions@inspire-7-finep.iam.gserviceaccount.com

      - name: Get secrets from Secret Manager
        id: secrets
        run: |
          echo "COGFY_API_KEY=$(gcloud secrets versions access latest --secret=cogfy-api-key)" >> $GITHUB_OUTPUT
          echo "DATABASE_URL=$(gcloud secrets versions access latest --secret=govbrnews-postgres-connection-string)" >> $GITHUB_OUTPUT
          echo "HF_TOKEN=$(gcloud secrets versions access latest --secret=hf-token)" >> $GITHUB_OUTPUT

      - name: Enrich dataset with AI-generated data
        run: |
          docker run --rm \
            -e COGFY_API_KEY="${{ steps.secrets.outputs.COGFY_API_KEY }}" \
            -e HF_TOKEN="${{ steps.secrets.outputs.HF_TOKEN }}" \
            -e STORAGE_BACKEND=dual_write \
            -e STORAGE_READ_FROM=postgres \
            -e DATABASE_URL="${{ steps.secrets.outputs.DATABASE_URL }}" \
            ghcr.io/destaquesgovbr/data-platform:latest \
            data-platform enrich --start-date "${{ needs.setup-dates.outputs.start_date }}" --end-date "${{ needs.setup-dates.outputs.end_date }}"
          echo "Dataset enrichment completed successfully"

  generate-embeddings:
    name: Generate Semantic Embeddings
    runs-on: ubuntu-latest
    needs: [setup-dates, enrich-themes]
    steps:
      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ github.token }}

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/990583792367/locations/global/workloadIdentityPools/github-pool/providers/github-provider
          service_account: github-actions@inspire-7-finep.iam.gserviceaccount.com

      - name: Get secrets from Secret Manager
        id: secrets
        run: |
          echo "DATABASE_URL=$(gcloud secrets versions access latest --secret=govbrnews-postgres-connection-string)" >> $GITHUB_OUTPUT
          echo "EMBEDDINGS_API_KEY=$(gcloud secrets versions access latest --secret=embeddings-api-key)" >> $GITHUB_OUTPUT

      - name: Get identity token for Cloud Run
        id: identity
        run: |
          # Get identity token with impersonation (required for WIF)
          # Note: stderr goes to console (shows impersonation warning), only stdout goes to file
          echo "Getting identity token via impersonation..."
          if gcloud auth print-identity-token \
            --impersonate-service-account=github-actions@inspire-7-finep.iam.gserviceaccount.com \
            --audiences=https://destaquesgovbr-embeddings-api-990583792367.southamerica-east1.run.app \
            > /tmp/identity_token.txt; then
            echo "Successfully obtained identity token ($(wc -c < /tmp/identity_token.txt) bytes)"
            echo "TOKEN_FILE=/tmp/identity_token.txt" >> $GITHUB_OUTPUT
          else
            echo "::warning::Could not get identity token via impersonation."
            echo "TOKEN_FILE=" >> $GITHUB_OUTPUT
          fi

      - name: Generate embeddings for news articles
        run: |
          # Read token from file if available
          IDENTITY_TOKEN=""
          if [ -n "${{ steps.identity.outputs.TOKEN_FILE }}" ] && [ -f "${{ steps.identity.outputs.TOKEN_FILE }}" ]; then
            IDENTITY_TOKEN=$(cat "${{ steps.identity.outputs.TOKEN_FILE }}")
            echo "Using identity token from file"
          fi

          docker run --rm \
            -e DATABASE_URL="${{ steps.secrets.outputs.DATABASE_URL }}" \
            -e EMBEDDINGS_API_URL="https://destaquesgovbr-embeddings-api-990583792367.southamerica-east1.run.app" \
            -e EMBEDDINGS_API_KEY="${{ steps.secrets.outputs.EMBEDDINGS_API_KEY }}" \
            -e EMBEDDINGS_IDENTITY_TOKEN="$IDENTITY_TOKEN" \
            -e GOOGLE_APPLICATION_CREDENTIALS=/gcp/creds.json \
            -v "$GOOGLE_APPLICATION_CREDENTIALS:/gcp/creds.json:ro" \
            ghcr.io/destaquesgovbr/data-platform:latest \
            data-platform generate-embeddings --start-date "${{ needs.setup-dates.outputs.start_date }}" --end-date "${{ needs.setup-dates.outputs.end_date }}"
          echo "Embedding generation completed successfully"

  pipeline-summary:
    name: Pipeline Summary
    runs-on: ubuntu-latest
    needs: [setup-dates, scraper, ebc-scraper, upload-to-cogfy, enrich-themes, generate-embeddings]
    if: always()
    steps:
      - name: Pipeline completion summary
        run: |
          echo "=== News Processing Pipeline Summary ==="
          echo "Date range: ${{ needs.setup-dates.outputs.start_date }} to ${{ needs.setup-dates.outputs.end_date }}"
          echo "Scraper status: ${{ needs.scraper.result }}"
          echo "EBC Scraper status: ${{ needs.ebc-scraper.result }}"
          echo "Upload status: ${{ needs.upload-to-cogfy.result }}"
          echo "Dataset enrichment status: ${{ needs.enrich-themes.result }}"
          echo "Embedding generation status: ${{ needs.generate-embeddings.result }}"
          echo "============================================"

          if [ "${{ needs.scraper.result }}" = "success" ] && \
             [ "${{ needs.ebc-scraper.result }}" = "success" ] && \
             [ "${{ needs.upload-to-cogfy.result }}" = "success" ] && \
             [ "${{ needs.enrich-themes.result }}" = "success" ] && \
             [ "${{ needs.generate-embeddings.result }}" = "success" ]; then
            echo "All pipeline stages completed successfully!"
            exit 0
          else
            echo "Pipeline had failures. Check individual job logs."
            exit 1
          fi
